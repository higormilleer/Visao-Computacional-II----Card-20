{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de0abd2-d3bb-41ab-a21a-c973f5662feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b67c71-6c42-4cd5-b813-17c63ccf3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5]),\n",
    "    transforms.Lambda(lambda x: x.to(device))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab714532-0b3c-46d6-b485-ad3b74d92538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9.91M/9.91M [00:29<00:00, 336kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 201kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.65M/1.65M [00:00<00:00, 1.71MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 3.53MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trn_ds = MNIST('', transform=img_transform, train=True, download=True)\n",
    "val_ds = MNIST('', transform=img_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9499e46-e458-4da6-af21-c4afba03e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28,128), nn.ReLU(True),\n",
    "            nn.Linear(128,64), nn.ReLU(True),\n",
    "            nn.Linear(64,latent_dim))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim,64),nn.ReLU(True),\n",
    "            nn.Linear(64,128),nn.ReLU(True),\n",
    "            nn.Linear(128,28*28),nn.Tanh())\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(len(x), 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd87b297-ddc4-49fd-a397-61ce0f1f662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(input,model,criterio,optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = criterion(output,input)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_batch(input,model,criterion):\n",
    "    model.eval()\n",
    "    output = model(input)\n",
    "    loss = criterion(output,input)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46d4ab7-ae73-42a7-a11d-99505ae7f08f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Report' from 'fastprogress.fastprogress' (/opt/anaconda3/lib/python3.12/site-packages/fastprogress/fastprogress.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m master_bar, progress_bar\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastprogress\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Report\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoEncoder(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Report' from 'fastprogress.fastprogress' (/opt/anaconda3/lib/python3.12/site-packages/fastprogress/fastprogress.py)"
     ]
    }
   ],
   "source": [
    "from fastprogress import master_bar, progress_bar\n",
    "from fastprogress.fastprogress import Report\n",
    "\n",
    "model = AutoEncoder(3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 5\n",
    "log = Report(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    N = len(trn_dl)\n",
    "    for ix, (data,_) in enumerate(trn_dl):\n",
    "        loss = train_batch(data,model,criterion,optimizer)\n",
    "        log.record(pos=(epoch+(ix+1)/N), trn_loss=loss, end='\\r')\n",
    "\n",
    "    N = len(val_dl)\n",
    "    for ix, (data,_) in enumerate(val_dl):\n",
    "        loss = validate_batch(data,model,criterion)\n",
    "        log.record(pos=(epoch+(ix+1)/N),val_loss=loss,end='\\r')\n",
    "    log.report_avgs(epoch+1)\n",
    "log.plot(log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea81bda-0488-4e41-a855-430416262c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(3).to(device)\n",
    "\n",
    "for _ in range(3):\n",
    "    ix = np.random.randint(len(val_ds))\n",
    "    im, _ = val_ds[ix]\n",
    "    _im = model(im[None])[0]\n",
    "    fig, ax = plt.subplots(1,2,figsize=(3,3))\n",
    "    show(im[0], ax=ax[0], title='input')\n",
    "    show(_im[0], ax=ax[1], title='prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913255f3-7215-473c-9374-6e5cb1f86384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
