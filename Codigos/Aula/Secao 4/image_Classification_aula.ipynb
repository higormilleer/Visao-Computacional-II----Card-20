{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8871f9-cd0a-4bb4-bc0d-18b6b0943632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 26.4M/26.4M [01:56<00:00, 227kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST/raw/train-images-idx3-ubyte.gz to FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 173kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST/raw/train-labels-idx1-ubyte.gz to FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4.42M/4.42M [00:03<00:00, 1.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST/raw/t10k-images-idx3-ubyte.gz to FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5.15k/5.15k [00:00<00:00, 5.60MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "data_folder = ''\n",
    "fmnist = datasets.FashionMNIST(data_folder, download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b453aae-31ca-4e8a-938b-88a4b22c3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_images = fmnist.data\n",
    "tr_targets = fmnist.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5826c390-5165-465a-8d05-18a79edfa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fd310e-e4bd-4650-af71-abd1e15d30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = len(tr_targets.unique()), 10  # Define o número de linhas (R) como o número de classes únicas em `tr_targets` e o número de colunas (C) como 10.\n",
    "fig, ax = plt.subplots(R, C, figsize=(10, 10))  # Cria uma grade de subplots com R linhas e C colunas, com tamanho total de figura 10x10.\n",
    "\n",
    "for label_class, plot_row in enumerate(ax):  # Itera sobre cada classe de rótulo e suas respectivas linhas de subplots.\n",
    "    label_x_rows = np.where(tr_targets == label_class)[0]  # Encontra os índices das imagens pertencentes à classe atual.\n",
    "\n",
    "    for plot_cell in plot_row:  # Itera sobre as células (colunas) da linha atual.\n",
    "        plot_cell.grid(False); plot_cell.axis('off')  # Remove as grades e os eixos de cada subplot.\n",
    "        ix = np.random.choice(label_x_rows)  # Seleciona aleatoriamente um índice da classe atual.\n",
    "        x, y = tr_images[ix], tr_targets[ix]  # Obtém a imagem `x` e seu rótulo `y` a partir do índice selecionado.\n",
    "        plot_cell.imshow(x, cmap='gray')  # Exibe a imagem em escala de cinza na célula correspondente.\n",
    "\n",
    "plt.tight_layout()  # Ajusta automaticamente o espaçamento entre os subplots para evitar sobreposição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a78afb6-e4f3-4c99-a51e-4afa961ae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a7b05d-0f87-4b90-b2b0-acb1e86d5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNISTDataset(Dataset):  # Criação de uma classe personalizada de dataset para Fashion MNIST, herdando de `Dataset`.\n",
    "    def __init__(self, x, y):\n",
    "        x = x.float()  # Converte os dados `x` para o tipo `float`.\n",
    "        # Estamos achatando cada imagem, altura = largura = 28.\n",
    "        # -1 significa que as outras dimensões serão ajustadas automaticamente com base no número de elementos.\n",
    "        x = x.view(-1, 28*28)  # Redimensiona cada imagem 28x28 para um vetor unidimensional de tamanho 784.\n",
    "        self.x, self.y = x, y  # Salva os dados de entrada `x` e os rótulos `y`.\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]  # Obtém a entrada `x` e o rótulo `y` correspondentes ao índice fornecido.\n",
    "        return x.to(device), y.to(device)  # Transfere os dados para o dispositivo (CPU ou GPU) e os retorna.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)  # Retorna o número total de amostras no dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da01a9bc-d224-4cfa-bf09-bd413a54b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = FMNISTDataset(tr_images, tr_targets)\n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    return trn_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c91dd0-f751-4dd6-a45d-a0aac498b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o mdoelo\n",
    "from torch.optim import SGD\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(28 * 28, 1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1000,10)\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr = 1e-2)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9036b906-3a3a-4b59-8bb7-4412c7eeb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy_fn(x,y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    max_values, argmaxes = prediction.max(-1)\n",
    "    is_correct = argmaxes == y\n",
    "    return is_correct.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb7e81e-7962-4444-8318-e2e2c4f3eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()  # Coloca o modelo em modo de treinamento (habilita dropout, batch normalization, etc.).\n",
    "    prediction = model(x)  # Faz a previsão passando os dados de entrada `x` pelo modelo.\n",
    "    batch_loss = loss_fn(prediction, y)  # Calcula a perda (loss) comparando as previsões com os rótulos reais `y`.\n",
    "    batch_loss.backward()  # Calcula os gradientes através da retropropagação (backpropagation).\n",
    "    optimizer.step()  # Atualiza os pesos do modelo com base nos gradientes calculados.\n",
    "    # Limpa a memória dos gradientes para a próxima iteração.\n",
    "    optimizer.zero_grad()  \n",
    "    return batch_loss.item()  # Retorna o valor da perda como um número escalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1099505-b36f-4e85-a2e2-cd03723c83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52472740-40dd-4718-a6c5-2078cd49d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = [], []\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    epoch_losses, epoch_accuracies = [], []\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "        epoch_losses.append(batch_loss)\n",
    "    epoch_loss = np.array(epoch_losses).mean()\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        is_correct = accuracy_fn(x, y, model)\n",
    "        epoch_accuracies.extend(is_correct)\n",
    "    epoch_accuracy = np.mean(epoch_accuracies)\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5c8fea-a623-4c65-9e8f-99044a675cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16c91b350>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = np.arange(5) + 1  # Cria um array com os valores das épocas (1 a 5)\n",
    "plt.figure(figsize=(20, 5))  # Define o tamanho da figura\n",
    "\n",
    "# Gráfico da perda\n",
    "plt.subplot(121)\n",
    "plt.title('Loss value over increasing epochs')  # Título do gráfico\n",
    "plt.plot(epochs, losses, label='Training Loss')  # Plota os valores da perda\n",
    "plt.legend()  # Exibe a legenda\n",
    "\n",
    "# Gráfico da acurácia\n",
    "plt.subplot(122)\n",
    "plt.title('Accuracy value over increasing epochs')  # Título do gráfico\n",
    "plt.plot(epochs, accuracies, label='Training Accuracy')  # Plota os valores da acurácia\n",
    "\n",
    "# Define ticks fixos antes de personalizar os rótulos do eixo Y\n",
    "yticks = plt.gca().get_yticks()  # Obtém os ticks atuais\n",
    "plt.gca().set_yticks(yticks)  # Define os ticks explicitamente\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x * 100) for x in yticks])  # Converte os rótulos para porcentagem\n",
    "plt.legend()  # Exibe a legenda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e65229-356d-49bf-af78-0c2cfaf64d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
