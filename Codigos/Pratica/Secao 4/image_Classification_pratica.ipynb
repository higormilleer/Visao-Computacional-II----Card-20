{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c96428-f799-48dd-8825-c09100506ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "data_folder = ''\n",
    "fmnist = datasets.FashionMNIST(data_folder, download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc21f10-b9d5-44a0-92d0-1669e7f41199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_images = fmnist.data\n",
    "tr_targets = fmnist.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de0a4c1-f73e-42d6-952d-43d02bdf90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "R, C = len(tr_targets.unique()), 10  # Define o número de linhas (R) como o número de classes únicas em `tr_targets` e o número de colunas (C) como 10.\n",
    "fig, ax = plt.subplots(R, C, figsize=(10, 10))  # Cria uma grade de subplots com R linhas e C colunas, com tamanho total de figura 10x10.\n",
    "\n",
    "for label_class, plot_row in enumerate(ax):  # Itera sobre cada classe de rótulo e suas respectivas linhas de subplots.\n",
    "    label_x_rows = np.where(tr_targets == label_class)[0]  # Encontra os índices das imagens pertencentes à classe atual.\n",
    "\n",
    "    for plot_cell in plot_row:  # Itera sobre as células (colunas) da linha atual.\n",
    "        plot_cell.grid(False); plot_cell.axis('off')  # Remove as grades e os eixos de cada subplot.\n",
    "        ix = np.random.choice(label_x_rows)  # Seleciona aleatoriamente um índice da classe atual.\n",
    "        x, y = tr_images[ix], tr_targets[ix]  # Obtém a imagem `x` e seu rótulo `y` a partir do índice selecionado.\n",
    "        plot_cell.imshow(x, cmap='gray')  # Exibe a imagem em escala de cinza na célula correspondente.\n",
    "\n",
    "plt.tight_layout()  # Ajusta automaticamente o espaçamento entre os subplots para evitar sobreposição.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48573b43-1303-442e-b6f4-8fabfca23e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from torchvision import datasets\n",
    "\n",
    "class FMNISTDataset(Dataset):  # Criação de uma classe personalizada de dataset para Fashion MNIST, herdando de `Dataset`.\n",
    "    def __init__(self, x, y):\n",
    "        x = x.float()  # Converte os dados `x` para o tipo `float`.\n",
    "        # Estamos achatando cada imagem, altura = largura = 28.\n",
    "        # -1 significa que as outras dimensões serão ajustadas automaticamente com base no número de elementos.\n",
    "        x = x.view(-1, 28*28)  # Redimensiona cada imagem 28x28 para um vetor unidimensional de tamanho 784.\n",
    "        self.x, self.y = x, y  # Salva os dados de entrada `x` e os rótulos `y`.\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]  # Obtém a entrada `x` e o rótulo `y` correspondentes ao índice fornecido.\n",
    "        return x.to(device), y.to(device)  # Transfere os dados para o dispositivo (CPU ou GPU) e os retorna.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)  # Retorna o número total de amostras no dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f5e926-3cc2-4af5-9866-be367c4eaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = FMNISTDataset(tr_images, tr_targets)\n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    return trn_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d6320d-1611-4a5a-b7d7-be67b75335b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterei o modelo reduzindo a quantidade de unidades na camada\n",
    "\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_model():\n",
    "    # Modifiquei a estrutura do modelo, adicionando uma camada intermediária\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(28 * 28, 512),        # Reduzi a quantidade de unidades da camada\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),                 # Adicionei dropout para regularização\n",
    "        nn.Linear(512, 10)               # Camada de saída\n",
    "    ).to(device)\n",
    "    \n",
    "    # Mantive a função de perda CrossEntropy\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Modifiquei o otimizador, agora com SGD e Momentum\n",
    "    optimizer = SGD(model.parameters(), lr=1e-2, momentum=0.9)  # Usando momentum para melhorar a convergência\n",
    "    \n",
    "    return model, loss_fn, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86af0239-f166-48fe-8a97-6c6e8f6096d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy_fn(x,y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    max_values, argmaxes = prediction.max(-1)\n",
    "    is_correct = argmaxes == y\n",
    "    return is_correct.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd37b22-5a1f-470c-969f-6e9f1a6f9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()  # Coloca o modelo em modo de treinamento (habilita dropout, batch normalization, etc.).\n",
    "    prediction = model(x)  # Faz a previsão passando os dados de entrada `x` pelo modelo.\n",
    "    batch_loss = loss_fn(prediction, y)  # Calcula a perda (loss) comparando as previsões com os rótulos reais `y`.\n",
    "    batch_loss.backward()  # Calcula os gradientes através da retropropagação (backpropagation).\n",
    "    optimizer.step()  # Atualiza os pesos do modelo com base nos gradientes calculados.\n",
    "    # Limpa a memória dos gradientes para a próxima iteração.\n",
    "    optimizer.zero_grad()  \n",
    "    return batch_loss.item()  # Retorna o valor da perda como um número escalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d46389-744e-4b41-834b-70bd155e01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24014699-654c-4643-88e4-af1950d84431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = [], []\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    epoch_losses, epoch_accuracies = [], []\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "        epoch_losses.append(batch_loss)\n",
    "    epoch_loss = np.array(epoch_losses).mean()\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        is_correct = accuracy_fn(x, y, model)\n",
    "        epoch_accuracies.extend(is_correct)\n",
    "    epoch_accuracy = np.mean(epoch_accuracies)\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b695da01-c0ec-4040-92f1-a5285e0a348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16c321100>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = np.arange(5) + 1  # Cria um array com os valores das épocas (1 a 5)\n",
    "plt.figure(figsize=(20, 5))  # Define o tamanho da figura\n",
    "\n",
    "# Gráfico da perda\n",
    "plt.subplot(121)\n",
    "plt.title('Loss value over increasing epochs')  # Título do gráfico\n",
    "plt.plot(epochs, losses, label='Training Loss')  # Plota os valores da perda\n",
    "plt.legend()  # Exibe a legenda\n",
    "\n",
    "# Gráfico da acurácia\n",
    "plt.subplot(122)\n",
    "plt.title('Accuracy value over increasing epochs')  # Título do gráfico\n",
    "plt.plot(epochs, accuracies, label='Training Accuracy')  # Plota os valores da acurácia\n",
    "\n",
    "# Define ticks fixos antes de personalizar os rótulos do eixo Y\n",
    "yticks = plt.gca().get_yticks()  # Obtém os ticks atuais\n",
    "plt.gca().set_yticks(yticks)  # Define os ticks explicitamente\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x * 100) for x in yticks])  # Converte os rótulos para porcentagem\n",
    "plt.legend()  # Exibe a legenda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135f402-4986-4ab3-88b6-dc0b79636a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
